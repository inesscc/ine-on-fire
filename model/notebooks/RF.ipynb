{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "\n",
    "from wildfire_forecasting.datamodules.datasets.greecefire_dataset import FireDataset_npy\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_dynamic_features = [\n",
    "    '1 km 16 days NDVI',\n",
    "#    '1 km 16 days EVI',\n",
    "#    'ET_500m',\n",
    "    'LST_Day_1km',\n",
    "    'LST_Night_1km',\n",
    "#    'Fpar_500m',\n",
    "#    'Lai_500m',\n",
    "#    'era5_max_u10',\n",
    "#    'era5_max_v10',\n",
    "    'era5_max_d2m',\n",
    "    'era5_max_t2m',\n",
    "    'era5_max_sp',\n",
    "    'era5_max_tp',\n",
    "#    'era5_min_u10',\n",
    "#    'era5_min_v10',\n",
    "#    'era5_min_d2m',\n",
    "#    'era5_min_t2m',\n",
    "#    'era5_min_sp',\n",
    "#    'era5_min_tp',\n",
    "#    'era5_avg_u10',\n",
    "#    'era5_avg_v10',\n",
    "#    'era5_avg_d2m',\n",
    "#    'era5_avg_t2m',\n",
    "#    'era5_avg_sp',\n",
    "#    'era5_avg_tp',\n",
    "#    'smian',\n",
    "    'sminx',\n",
    "#    'fwi',\n",
    "#    'era5_max_wind_u10',\n",
    "#    'era5_max_wind_v10',\n",
    "    'era5_max_wind_speed',\n",
    "#    'era5_max_wind_direction',\n",
    "#    'era5_max_rh',\n",
    "    'era5_min_rh',\n",
    "#    'era5_avg_rh',\n",
    "]\n",
    "\n",
    "\n",
    "sel_static_features = [\n",
    " 'dem_mean',\n",
    "# 'aspect_mean',\n",
    " 'slope_mean',\n",
    "# 'roughness_mean',\n",
    " 'roads_distance',\n",
    " 'waterway_distance',\n",
    " 'population_density',\n",
    "]\n",
    "\n",
    "clc = 'vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !IMPORTANT fill the path with path of the dataset you have downloaded\n",
    "dataset_root = Path(None)\n",
    "\n",
    "dataloaders = {\n",
    "    'train' : torch.utils.data.DataLoader(FireDataset_npy(dataset_root=dataset_root, train_val_test='train', access_mode='temporal', static_features=sel_static_features, dynamic_features=sel_dynamic_features, clc = clc), batch_size=1, shuffle=True, num_workers=16),\n",
    "    'val' : torch.utils.data.DataLoader(FireDataset_npy(dataset_root = dataset_root, train_val_test='val', access_mode = 'temporal', static_features=sel_static_features, dynamic_features=sel_dynamic_features, clc = clc), batch_size=1, num_workers=16),\n",
    "    'test': torch.utils.data.DataLoader(FireDataset_npy(dataset_root = dataset_root, train_val_test='test', access_mode = 'temporal', static_features=sel_static_features, dynamic_features=sel_dynamic_features, clc = clc), batch_size=1, num_workers=16),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training, val and test datasets\n",
    "X_train = []\n",
    "X_val = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_val = []\n",
    "y_test = []\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    for i, (dynamic, static, clc, label) in enumerate(dataloaders['train']):\n",
    "        dynamic_avg = torch.from_numpy(np.nanmean(dynamic.numpy(), axis=1))\n",
    "        input_ = torch.cat([dynamic_avg.squeeze(), dynamic[:,-1,:].squeeze(), static.squeeze(), clc.squeeze()], dim = 0)\n",
    "        input_ = input_.numpy()\n",
    "        X_train.append(input_)\n",
    "        y_train.append(label.numpy())\n",
    "\n",
    "    for i, (dynamic, static, clc, label) in enumerate(dataloaders['val']):\n",
    "        dynamic_avg = torch.from_numpy(np.nanmean(dynamic.numpy(), axis=1))\n",
    "        input_ = torch.cat([dynamic_avg.squeeze(), dynamic[:,-1,:].squeeze(), static.squeeze(), clc.squeeze()], dim = 0)\n",
    "        input_ = input_.numpy()\n",
    "        X_val.append(input_)\n",
    "        y_val.append(label.numpy())\n",
    "\n",
    "    for i, (dynamic, static, clc, label) in enumerate(dataloaders['test']):\n",
    "        dynamic_avg = torch.from_numpy(np.nanmean(dynamic.numpy(), axis=1))\n",
    "        input_ = torch.cat([dynamic_avg.squeeze(), dynamic[:,-1,:].squeeze(), static.squeeze(), clc.squeeze()], dim = 0)\n",
    "        input_ = input_.numpy()\n",
    "        X_test.append(input_)\n",
    "        y_test.append(label.numpy())\n",
    "\n",
    "X_train = np.stack(X_train, axis=0)\n",
    "y_train = np.stack(y_train, axis=0)\n",
    "X_val = np.stack(X_val, axis=0)\n",
    "y_val = np.stack(y_val, axis=0)\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "y_test = np.stack(y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 100\n",
    "max_depth = 10\n",
    "min_samples_split = 2\n",
    "min_samples_leaf = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=n_est, max_depth = max_depth, min_samples_split=min_samples_split, \n",
    "                             min_samples_leaf = min_samples_leaf, random_state=123)\n",
    "clf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "probs_pred = clf.predict_proba(X_test)[:,1]\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "y_test = np.stack(y_test, axis=0)\n",
    "auc = roc_auc_score(y_test, probs_pred)\n",
    "aucpr = average_precision_score(y_test, probs_pred)\n",
    "\n",
    "print(auc)\n",
    "print(aucpr)\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# filename = 'rf.sav'\n",
    "# pickle.dump(clf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo-env",
   "language": "python",
   "name": "geo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
